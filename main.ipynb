{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_train = tf.cast(x_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(x_test)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      5\n",
       "1      0\n",
       "2      4\n",
       "3      1\n",
       "4      9\n",
       "...   ..\n",
       "59995  8\n",
       "59996  3\n",
       "59997  5\n",
       "59998  6\n",
       "59999  8\n",
       "\n",
       "[60000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0_0    0_1    0_2    0_3    0_4    0_5    0_6    0_7    0_8    0_9\n",
      "0      False  False  False  False  False   True  False  False  False  False\n",
      "1       True  False  False  False  False  False  False  False  False  False\n",
      "2      False  False  False  False   True  False  False  False  False  False\n",
      "3      False   True  False  False  False  False  False  False  False  False\n",
      "4      False  False  False  False  False  False  False  False  False   True\n",
      "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
      "59995  False  False  False  False  False  False  False  False   True  False\n",
      "59996  False  False  False   True  False  False  False  False  False  False\n",
      "59997  False  False  False  False  False   True  False  False  False  False\n",
      "59998  False  False  False  False  False  False   True  False  False  False\n",
      "59999  False  False  False  False  False  False  False  False   True  False\n",
      "\n",
      "[60000 rows x 10 columns]\n",
      "       0_0  0_1  0_2  0_3  0_4  0_5  0_6  0_7  0_8  0_9\n",
      "0        0    0    0    0    0    1    0    0    0    0\n",
      "1        1    0    0    0    0    0    0    0    0    0\n",
      "2        0    0    0    0    1    0    0    0    0    0\n",
      "3        0    1    0    0    0    0    0    0    0    0\n",
      "4        0    0    0    0    0    0    0    0    0    1\n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "59995    0    0    0    0    0    0    0    0    1    0\n",
      "59996    0    0    0    1    0    0    0    0    0    0\n",
      "59997    0    0    0    0    0    1    0    0    0    0\n",
      "59998    0    0    0    0    0    0    1    0    0    0\n",
      "59999    0    0    0    0    0    0    0    0    1    0\n",
      "\n",
      "[60000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "y_train= pd.get_dummies(df, columns = [0]) \n",
    "print(y_train)\n",
    "y_train = y_train.astype(int)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     7\n",
       "1     2\n",
       "2     1\n",
       "3     0\n",
       "4     4\n",
       "...  ..\n",
       "9995  2\n",
       "9996  3\n",
       "9997  4\n",
       "9998  5\n",
       "9999  6\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.DataFrame(y_test)\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0_0    0_1    0_2    0_3    0_4    0_5    0_6    0_7    0_8    0_9\n",
      "0     False  False  False  False  False  False  False   True  False  False\n",
      "1     False  False   True  False  False  False  False  False  False  False\n",
      "2     False   True  False  False  False  False  False  False  False  False\n",
      "3      True  False  False  False  False  False  False  False  False  False\n",
      "4     False  False  False  False   True  False  False  False  False  False\n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
      "9995  False  False   True  False  False  False  False  False  False  False\n",
      "9996  False  False  False   True  False  False  False  False  False  False\n",
      "9997  False  False  False  False   True  False  False  False  False  False\n",
      "9998  False  False  False  False  False   True  False  False  False  False\n",
      "9999  False  False  False  False  False  False   True  False  False  False\n",
      "\n",
      "[10000 rows x 10 columns]\n",
      "      0_0  0_1  0_2  0_3  0_4  0_5  0_6  0_7  0_8  0_9\n",
      "0       0    0    0    0    0    0    0    1    0    0\n",
      "1       0    0    1    0    0    0    0    0    0    0\n",
      "2       0    1    0    0    0    0    0    0    0    0\n",
      "3       1    0    0    0    0    0    0    0    0    0\n",
      "4       0    0    0    0    1    0    0    0    0    0\n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "9995    0    0    1    0    0    0    0    0    0    0\n",
      "9996    0    0    0    1    0    0    0    0    0    0\n",
      "9997    0    0    0    0    1    0    0    0    0    0\n",
      "9998    0    0    0    0    0    1    0    0    0    0\n",
      "9999    0    0    0    0    0    0    1    0    0    0\n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "y_test= pd.get_dummies(dft, columns= [0])\n",
    "print(y_test)\n",
    "y_test = y_test.astype(int)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_h1 = 392\n",
    "n_h2 = 196\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1' : tf.random.uniform([n_input,n_h1],minval=-1.0,maxval=1.0),\n",
    "    'h2' : tf.random.uniform([n_h1,n_h2],minval=-1.0,maxval=1.0),\n",
    "    'out' : tf.random.uniform([n_h2,n_out],minval=-1.0,maxval=1.0)\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'h1' : tf.random.uniform([n_h1],minval=-1.0,maxval=1.0),\n",
    "    'h2' : tf.random.uniform([n_h2],minval=-1.0,maxval=1.0),\n",
    "    'out' : tf.random.uniform([n_out],minval=-1.0,maxval=1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardpropogation(x,weights,bias):\n",
    "    in_layer1 = tf.add(tf.matmul(x,weights['h1']),bias['h1'])\n",
    "    out_layer1 = tf.nn.relu(in_layer1)\n",
    "\n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1,weights['h2']),bias['h2'])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "\n",
    "    output = tf.add(tf.matmul(out_layer2,weights['out']),bias['out'])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(60000,), dtype=float32, numpy=array([5., 5., 0., ..., 5., 5., 5.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(60000,), dtype=float32, numpy=array([5., 0., 4., ..., 5., 6., 8.], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = forwardpropogation(x_train,weights,bias)\n",
    "y_pred = tf.argmax(y_pred,1)\n",
    "y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "y_train = tf.argmax(y_train,1)\n",
    "y_train = tf.cast(y_train, dtype=tf.float32)\n",
    "y_pred,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000,), dtype=bool, numpy=array([ True, False, False, ...,  True, False, False])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred = tf.equal(y_pred,y_train)\n",
    "count = 0\n",
    "correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False ...  True False False]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "correct_pred_np = correct_pred.numpy()\n",
    "print(correct_pred_np)\n",
    "print(correct_pred_np[0])\n",
    "\n",
    "for e in correct_pred_np:\n",
    "    if(e == 'True'):\n",
    "        print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(correct_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6880, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "sum_correct_pred = tf.reduce_sum(tf.cast(correct_pred, dtype=tf.int32))\n",
    "print(sum_correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3362985.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = tf.nn.softmax_cross_entropy_with_logits(labels=y_train,logits=y_pred)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'h1': <tf.Tensor: shape=(784, 392), dtype=float32, numpy=\n",
       "  array([[-0.33704638,  0.4691062 ,  0.20533013, ...,  0.6025193 ,\n",
       "          -0.3183782 , -0.60153556],\n",
       "         [ 0.67788005,  0.04707813,  0.1423192 , ..., -0.25594616,\n",
       "          -0.35294318, -0.43114758],\n",
       "         [-0.592566  , -0.41960979, -0.6248834 , ..., -0.02429056,\n",
       "           0.591661  , -0.6601517 ],\n",
       "         ...,\n",
       "         [ 0.15508318, -0.08495307, -0.57480764, ...,  0.12809825,\n",
       "          -0.5421853 ,  0.72237444],\n",
       "         [-0.23559332,  0.52002907,  0.24465942, ...,  0.79031134,\n",
       "          -0.68506765,  0.8047364 ],\n",
       "         [-0.29866552, -0.89156675,  0.04043484, ..., -0.25790906,\n",
       "           0.45103693,  0.7264869 ]], dtype=float32)>,\n",
       "  'h2': <tf.Tensor: shape=(392, 196), dtype=float32, numpy=\n",
       "  array([[-0.21190596, -0.57082915, -0.4147687 , ..., -0.640692  ,\n",
       "           0.02685237, -0.46231604],\n",
       "         [-0.69732   , -0.21929288, -0.37001038, ...,  0.17741585,\n",
       "          -0.4143219 ,  0.537276  ],\n",
       "         [ 0.40698123, -0.34086394,  0.77980375, ...,  0.0088861 ,\n",
       "          -0.6743624 ,  0.43207192],\n",
       "         ...,\n",
       "         [ 0.1631968 , -0.8641913 , -0.75374746, ...,  0.8340614 ,\n",
       "          -0.5062628 ,  0.30814004],\n",
       "         [ 0.2157538 ,  0.6889069 ,  0.69351006, ..., -0.33908582,\n",
       "           0.21205282,  0.29514456],\n",
       "         [ 0.41441083,  0.47675776, -0.68670654, ...,  0.45438576,\n",
       "          -0.4467411 , -0.57473135]], dtype=float32)>,\n",
       "  'out': <tf.Tensor: shape=(196, 10), dtype=float32, numpy=\n",
       "  array([[-0.32027006, -0.8270078 , -0.5152626 , ..., -0.03628898,\n",
       "          -0.47434163, -0.7827461 ],\n",
       "         [ 0.2409749 ,  0.13532567,  0.76976347, ...,  0.13723159,\n",
       "           0.10803866, -0.62088156],\n",
       "         [-0.660151  ,  0.8834567 , -0.02988029, ..., -0.8643589 ,\n",
       "           0.5395522 , -0.87486124],\n",
       "         ...,\n",
       "         [-0.50266695, -0.19180655,  0.804126  , ..., -0.27874708,\n",
       "          -0.929142  ,  0.78873897],\n",
       "         [ 0.23796535, -0.7601402 ,  0.22689342, ...,  0.53746915,\n",
       "          -0.72731113, -0.506094  ],\n",
       "         [-0.39639616,  0.14363718,  0.66944075, ..., -0.29591346,\n",
       "           0.63776135,  0.34940696]], dtype=float32)>},\n",
       " {'h1': <tf.Tensor: shape=(392,), dtype=float32, numpy=\n",
       "  array([-0.5971246 , -0.886878  , -0.47143602,  0.47695446, -0.20600581,\n",
       "         -0.84837914,  0.3122468 ,  0.6984029 ,  0.32317066,  0.12873101,\n",
       "          0.16179824, -0.44639826, -0.8557265 ,  0.33503866,  0.8683779 ,\n",
       "          0.8358636 ,  0.62617755,  0.6975372 ,  0.05251551, -0.54761124,\n",
       "         -0.17747426, -0.73428655, -0.70908546,  0.9456389 ,  0.15263343,\n",
       "          0.34860206,  0.2723143 , -0.3308475 , -0.02020478, -0.44533515,\n",
       "          0.9939511 , -0.03063703,  0.92345786, -0.5076425 ,  0.83058333,\n",
       "          0.48203325, -0.58147883,  0.67902756, -0.08925247,  0.5586436 ,\n",
       "         -0.8409567 ,  0.10994196, -0.6168585 ,  0.2620573 ,  0.19518924,\n",
       "         -0.11707711, -0.37095952, -0.9457791 ,  0.30326366,  0.89448524,\n",
       "          0.16947961, -0.9058852 ,  0.4635024 , -0.55649185,  0.88276124,\n",
       "          0.41487288, -0.8312681 , -0.6234417 ,  0.33239603,  0.26070738,\n",
       "         -0.9612725 ,  0.79566646,  0.40219712, -0.2921059 , -0.44362593,\n",
       "          0.0481348 ,  0.55144095,  0.6522436 , -0.36325908, -0.16964507,\n",
       "          0.3880291 , -0.5313535 ,  0.3554237 ,  0.5029156 ,  0.46810174,\n",
       "         -0.6548829 ,  0.01933956,  0.25416017,  0.4868369 ,  0.5804255 ,\n",
       "          0.30297875,  0.49939942, -0.9309399 ,  0.6142719 , -0.5872688 ,\n",
       "         -0.24252868, -0.62603784,  0.20264006, -0.45982456, -0.338624  ,\n",
       "         -0.40304828, -0.95422983,  0.20505977, -0.9264889 ,  0.26974416,\n",
       "         -0.49073005, -0.10741925, -0.14863133, -0.87996006, -0.06303859,\n",
       "         -0.24251056,  0.324008  , -0.45855165, -0.32528377, -0.4304738 ,\n",
       "         -0.72265625, -0.63423586,  0.864702  ,  0.10605216,  0.80006695,\n",
       "         -0.6930094 , -0.40007687, -0.24066067, -0.3132949 ,  0.7177086 ,\n",
       "         -0.1568942 , -0.8139212 , -0.39132237,  0.8906889 ,  0.8060601 ,\n",
       "          0.09272194,  0.44141865, -0.01171756,  0.93249536, -0.5597718 ,\n",
       "          0.28714824, -0.25847888,  0.21336389,  0.7266171 ,  0.4462974 ,\n",
       "          0.6960161 ,  0.99292135, -0.22963333,  0.384233  ,  0.3169601 ,\n",
       "         -0.8959429 , -0.90544295, -0.6795492 ,  0.19951987,  0.02857089,\n",
       "         -0.10205531,  0.1553626 , -0.3173163 , -0.29584622,  0.90455365,\n",
       "          0.24765038,  0.5560608 ,  0.43175173,  0.4865923 ,  0.8207984 ,\n",
       "         -0.9083481 ,  0.9472196 , -0.02777052, -0.8406942 ,  0.07188344,\n",
       "         -0.3726318 , -0.09450984, -0.06972003, -0.04718375, -0.43374205,\n",
       "          0.9489713 , -0.71358633,  0.28301334, -0.09232903,  0.02558589,\n",
       "         -0.4299662 ,  0.05234194, -0.08569694, -0.20119166,  0.6086681 ,\n",
       "          0.58633995, -0.05050278,  0.03608918,  0.4888518 ,  0.42986202,\n",
       "         -0.4232583 ,  0.52314615,  0.01148391,  0.82995963, -0.9822123 ,\n",
       "         -0.36508322,  0.8512995 ,  0.06306243, -0.39945984,  0.66376734,\n",
       "          0.29611826,  0.57972264, -0.26893854,  0.56119657,  0.80551195,\n",
       "         -0.81684947,  0.48859334,  0.8880048 ,  0.20171928,  0.7261679 ,\n",
       "         -0.90423226,  0.76319146,  0.703604  , -0.00859618, -0.4340706 ,\n",
       "          0.427289  ,  0.88797784, -0.08982801, -0.2993157 , -0.29291344,\n",
       "          0.8983357 , -0.73784304, -0.9490416 , -0.60520744,  0.77718186,\n",
       "          0.20851922,  0.79533315, -0.52111363, -0.51438355,  0.14807439,\n",
       "          0.08035445, -0.20390916, -0.9455943 , -0.21976662,  0.12832165,\n",
       "          0.5700519 , -0.37985134, -0.82231736,  0.7218199 , -0.310215  ,\n",
       "          0.91102505,  0.7408292 , -0.88407254,  0.8435652 ,  0.6870158 ,\n",
       "          0.7156787 , -0.9740491 ,  0.7386234 , -0.53047156, -0.28542066,\n",
       "         -0.35983753, -0.7094197 ,  0.11975956,  0.93267846,  0.51609635,\n",
       "          0.8421836 , -0.5286529 , -0.27134132, -0.6137099 , -0.16026855,\n",
       "          0.58612347, -0.15376544, -0.63325906,  0.8645561 , -0.18233132,\n",
       "          0.5271909 ,  0.70457625, -0.00671721,  0.5061066 ,  0.47713995,\n",
       "          0.32131195,  0.956516  , -0.81620026, -0.07763577,  0.09620404,\n",
       "          0.999382  ,  0.65057206,  0.65953255, -0.06223035,  0.3361888 ,\n",
       "          0.22295094, -0.78401995, -0.26852798, -0.8066938 ,  0.21216083,\n",
       "          0.377187  ,  0.9008069 ,  0.43391705,  0.0307703 , -0.70319843,\n",
       "          0.62778425, -0.03122234, -0.55116415,  0.6598065 , -0.52428484,\n",
       "          0.2712388 ,  0.3649423 ,  0.14021349, -0.74714494, -0.76596713,\n",
       "         -0.8480513 , -0.4465263 ,  0.61230946,  0.0440681 , -0.50592995,\n",
       "         -0.10334945, -0.6779535 ,  0.0820384 ,  0.7574837 ,  0.02581525,\n",
       "         -0.05308199,  0.5965085 , -0.31662703,  0.10177946,  0.9019964 ,\n",
       "          0.88873863,  0.66715264,  0.34915352, -0.67673063,  0.87094307,\n",
       "          0.85332656, -0.56881285,  0.48783422,  0.8684263 , -0.79583645,\n",
       "         -0.4360206 ,  0.66906977, -0.30075526,  0.50562   , -0.23024225,\n",
       "          0.3103783 ,  0.9630754 ,  0.78863406, -0.61551094,  0.62528896,\n",
       "         -0.5334492 ,  0.641206  , -0.6766746 , -0.9889171 ,  0.99183106,\n",
       "         -0.75852203,  0.00203443,  0.21851373,  0.17522001, -0.4390471 ,\n",
       "          0.08079791,  0.8318372 , -0.5203693 , -0.36545634, -0.9619801 ,\n",
       "         -0.5727539 , -0.5534868 ,  0.66982245,  0.48150277, -0.5166631 ,\n",
       "          0.24911594,  0.982033  ,  0.61282015,  0.8075235 , -0.51061654,\n",
       "          0.5034802 ,  0.9548013 ,  0.870095  , -0.56231904,  0.94899416,\n",
       "         -0.2773447 , -0.9429543 ,  0.03839636, -0.37236643, -0.59848404,\n",
       "          0.5958111 ,  0.11134315,  0.34422088,  0.8089025 ,  0.6579354 ,\n",
       "          0.5179825 , -0.18915343,  0.2036593 , -0.9879842 , -0.21535611,\n",
       "          0.5901499 , -0.90544605, -0.21888685,  0.9425037 ,  0.74912   ,\n",
       "         -0.07834268, -0.84618735,  0.62864804,  0.29124522,  0.61077404,\n",
       "         -0.8765428 ,  0.37068343, -0.76299715,  0.9493301 ,  0.54385257,\n",
       "          0.85706663, -0.3477242 ,  0.20713568, -0.20094109,  0.2912593 ,\n",
       "          0.32275176,  0.20857692,  0.75755763, -0.3359344 , -0.63212895,\n",
       "         -0.2723472 ,  0.2615447 ], dtype=float32)>,\n",
       "  'h2': <tf.Tensor: shape=(196,), dtype=float32, numpy=\n",
       "  array([ 0.7371063 ,  0.25960517, -0.19778252, -0.8055105 , -0.38781023,\n",
       "          0.70112514, -0.62773895,  0.8206327 ,  0.9222915 ,  0.18363786,\n",
       "         -0.31974196,  0.9301572 ,  0.28164387,  0.5859685 , -0.29908133,\n",
       "         -0.9373121 , -0.9506283 , -0.88147783,  0.8751476 , -0.1763041 ,\n",
       "          0.6390586 , -0.10696936, -0.00159121, -0.61512375,  0.65841293,\n",
       "         -0.21949697, -0.32269526,  0.42840075,  0.24993062,  0.8087599 ,\n",
       "         -0.9933362 , -0.0357244 ,  0.02741742, -0.346802  ,  0.0984447 ,\n",
       "         -0.2922871 , -0.8939688 ,  0.7330985 , -0.9946475 , -0.5278642 ,\n",
       "          0.07295895,  0.6498811 ,  0.21200371,  0.71313953, -0.34544182,\n",
       "          0.42438507,  0.42972326, -0.03771019,  0.298419  , -0.11429214,\n",
       "          0.72493935, -0.92826486,  0.85157084, -0.14297652, -0.09331775,\n",
       "         -0.19581461, -0.5759983 , -0.21995926,  0.01208925, -0.31060052,\n",
       "         -0.24468565,  0.6065161 ,  0.45812345, -0.7514932 , -0.5174961 ,\n",
       "          0.8710017 ,  0.9815147 , -0.5872803 , -0.7790024 , -0.66936827,\n",
       "         -0.50149846, -0.57120657,  0.4225955 ,  0.6062741 , -0.86639595,\n",
       "         -0.16739154,  0.77972674, -0.10771847, -0.52858615,  0.55056214,\n",
       "          0.36769032, -0.6135218 ,  0.09668517,  0.42927384,  0.4282756 ,\n",
       "         -0.11341071,  0.35785103,  0.13681388,  0.99780345,  0.3511548 ,\n",
       "         -0.64254856, -0.00937319,  0.15030575,  0.2239058 ,  0.36106467,\n",
       "         -0.86561155,  0.804852  , -0.6291661 ,  0.991081  ,  0.5689659 ,\n",
       "         -0.28299856, -0.98515296,  0.45933247, -0.18610907,  0.98550797,\n",
       "          0.6911161 ,  0.8410907 ,  0.90633154,  0.9528065 ,  0.17021918,\n",
       "          0.8223531 ,  0.89224815, -0.72744465,  0.44930124, -0.36769247,\n",
       "         -0.3276279 , -0.9673002 , -0.0898695 , -0.83702135, -0.78600717,\n",
       "         -0.27491307,  0.6280813 ,  0.43632483, -0.9680476 , -0.94559956,\n",
       "          0.8267245 , -0.23030186, -0.07218313, -0.5590255 ,  0.6059401 ,\n",
       "         -0.71885896,  0.66034484, -0.2930355 ,  0.5569751 ,  0.9627819 ,\n",
       "         -0.5331161 , -0.81615853, -0.93564105,  0.19598722,  0.1778171 ,\n",
       "          0.9824152 , -0.67638063,  0.7420733 ,  0.5494909 , -0.38572335,\n",
       "         -0.41103888,  0.22984242,  0.89173436, -0.8366473 , -0.67050076,\n",
       "          0.97411346,  0.88156986, -0.354213  , -0.11495686, -0.69893384,\n",
       "          0.19094086, -0.9760988 ,  0.97449136, -0.1297009 , -0.6122067 ,\n",
       "         -0.9098375 ,  0.3611548 , -0.24591446, -0.7798991 ,  0.82515097,\n",
       "         -0.09053993, -0.35771608, -0.21285081, -0.27101827, -0.73231983,\n",
       "          0.19392252, -0.65685606,  0.44595337,  0.92720556,  0.93732834,\n",
       "          0.3602767 ,  0.62057614, -0.12031579, -0.04335022,  0.12627673,\n",
       "          0.9780295 ,  0.3888855 ,  0.00423169,  0.96160555, -0.4571345 ,\n",
       "         -0.80827165,  0.5481818 ,  0.6121526 ,  0.6618712 ,  0.55317307,\n",
       "         -0.07600379, -0.41039467,  0.2782235 ,  0.48042703, -0.97816825,\n",
       "          0.2394836 ], dtype=float32)>,\n",
       "  'out': <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "  array([-0.232723  ,  0.00387478, -0.64003587,  0.21240616,  0.14257574,\n",
       "         -0.3910365 ,  0.75325227, -0.6912    ,  0.33533525, -0.92765737],\n",
       "        dtype=float32)>}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_vars = [weights['h1'],bias['h1'],weights['h2'],bias['h2'],weights['out'],bias['out']]\n",
    "trainable_vars\n",
    "trainable_vars1 = [weights,bias]\n",
    "trainable_vars1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "# epochs = 10\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         # Forward pass\n",
    "#         y_pred = forwardpropogation(x_train,weights,bias)\n",
    "#         y_pred = tf.argmax(y_pred,1)\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "#         # Calculate the error using softmax_cross_entropy_with_logits\n",
    "#         error = tf.nn.softmax_cross_entropy_with_logits(labels=y_train, logits=y_pred)\n",
    "#         loss = tf.reduce_mean(error)\n",
    "\n",
    "#     # Compute gradients and apply them using the optimizer\n",
    "#     gradients = tape.gradient(loss,trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients,trainable_variables))\n",
    "\n",
    "#     print(f'Epoch {epoch + 1}, Loss: {loss.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`tape` is required when a `Tensor` loss is passed. Received: loss=3362985.0, tape=None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m optimize \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainable_vars\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:543\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[1;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m      None\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars)\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:262\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[1;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradients of loss on trainable variables.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03m  gradient can be `None`.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(loss) \u001b[38;5;129;01mand\u001b[39;00m tape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tape` is required when a `Tensor` loss is passed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, tape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m     )\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     tape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mGradientTape()\n",
      "\u001b[1;31mValueError\u001b[0m: `tape` is required when a `Tensor` loss is passed. Received: loss=3362985.0, tape=None."
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(error,var_list = trainable_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Tensor.name is undefined when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     cost_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax_cross_entropy_with_logits(labels\u001b[38;5;241m=\u001b[39my_train, logits\u001b[38;5;241m=\u001b[39my_pred)\n\u001b[0;32m      6\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mgradient(cost_fn, trainable_vars)\n\u001b[1;32m----> 7\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1222\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1218\u001b[0m experimental_aggregate_gradients \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_aggregate_gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m )\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m-> 1222\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1184\u001b[0m, in \u001b[0;36mOptimizer.aggregate_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_reduce_sum_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\optimizers\\utils.py:33\u001b[0m, in \u001b[0;36mall_reduce_sum_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all-reduced gradients aggregated via summation.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m  List of (gradient, variable) pairs where gradients have been all-reduced.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads_and_vars)\n\u001b[1;32m---> 33\u001b[0m filtered_grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_empty_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filtered_grads_and_vars:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mstrategy_supports_no_merge_call():\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\optimizers\\utils.py:76\u001b[0m, in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     73\u001b[0m filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(filtered)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered:\n\u001b[1;32m---> 76\u001b[0m     variable \u001b[38;5;241m=\u001b[39m (\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m]\u001b[49m,)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided `grads_and_vars` is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrads_and_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vars_with_empty_grads:\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\keras\\src\\optimizers\\utils.py:76\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(filtered)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered:\n\u001b[1;32m---> 76\u001b[0m     variable \u001b[38;5;241m=\u001b[39m ([\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars],)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided `grads_and_vars` is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrads_and_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vars_with_empty_grads:\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:261\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    254\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    255\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    257\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91936\\Desktop\\digit recognition\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:550\u001b[0m, in \u001b[0;36m_EagerTensorBase.name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 550\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    551\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.name is undefined when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Tensor.name is undefined when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "epochs = 100 #(or however many iterations you want it to run)\n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape() as tp:\n",
    "        #your loss/cost function must always be contained within the gradient tape instantiation\n",
    "        cost_fn = tf.nn.softmax_cross_entropy_with_logits(labels=y_train, logits=y_pred)\n",
    "    gradients = tp.gradient(cost_fn, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
